---
title: "Fitting GP to lightcurve 80_ra271.352_dec-29.642_MAXIJ1803 in Stan"
execute: 
  echo: false
format: 
  html:
    toc: true
    df-print: default 
self-contained: true
number-sections: true
---

Notebook outlining the fitting of GP to thunderKAT lightcurve 80_ra271.352_dec-29.642_MAXIJ1803.

```{r}
#| message: false
library(conflicted)
library(ggplot2)
library(readr)
library(dplyr)
library(here)
library(cmdstanr)
library(posterior)
library(bayesplot)

color_scheme_set("brightblue")
register_knitr_engine(override = FALSE)

mcmc_plots <- function(fit, variables) {
  draws_arr <- fit$draws(format = "draws_array")
  mcmc_trace(draws_arr, pars = variables, facet_args = list(nrow = 2)) |> print()
  mcmc_dens(draws_arr, pars = variables, facet_args = list(nrow = 2)) |> print()
  mcmc_pairs(draws_arr, pars = variables, off_diag_fun = "hex") |> print()
}

plot_postpred <- function(fit, x, y, y_err, x_star, title) {
  postpred_draws <- as_draws_rvars(fit$draws("f_star"))
  
  ggplot() +
    aes(x = x_star) +
    geom_ribbon(aes(ymin = quantile(postpred_draws$f_star, probs = 0.16)[1,],
                    ymax = quantile(postpred_draws$f_star, probs = 0.84)[1,]),
                fill = "blue", alpha = 0.3) +
    geom_ribbon(aes(ymin = quantile(postpred_draws$f_star, probs = 0.05)[1,],
                    ymax = quantile(postpred_draws$f_star, probs = 0.95)[1,]),
                fill = "blue", alpha = 0.3) +
    geom_line(aes(y = median(postpred_draws$f_star)), colour = "black") +
    geom_linerange(aes(x = x, y = y, 
                       ymax = y + y_err, ymin = y - y_err), colour = "red")  +
    geom_point(aes(x = x, y = y), size = 2, colour = "red") +
    labs(x = "MJD", y = "Flux (Jy)", title = title) +
    theme_classic()
}

plot_PSD <- function(fit, nsamples = 200, title) {
  draws_subset <- 
    subset_draws(fit$draws(), 
                 variable = "f_star", 
                 draw = 1:nsamples) |> 
    as_draws_matrix() |> 
    t()

  spec <- spectrum(draws_subset, plot = FALSE)
  
  data.frame(
    frequency = spec$freq,
    power = spec$spec
  ) |> 
    rowwise() |> 
    mutate(q0.05 = quantile(c_across(starts_with("power.")), probs = 0.05),
           q0.16 = quantile(c_across(starts_with("power.")), probs = 0.16),
           median = median(c_across(starts_with("power."))),
           q0.84 = quantile(c_across(starts_with("power.")), probs = 0.84),
           q0.95 = quantile(c_across(starts_with("power.")), probs = 0.95)) |> 
    ggplot() +
    aes(x = frequency, y = median) +
    geom_ribbon(aes(ymin = q0.16, ymax = q0.84), fill = "blue", alpha = 0.3) +
    geom_ribbon(aes(ymin = q0.05, ymax = q0.95), fill = "blue", alpha = 0.3) +
    geom_line() +
    scale_x_log10() +
    scale_y_log10() +
    labs(x = "Frequency", y = "Spectral Density", title = title) +
    theme_bw()
}
```

# Light Curve

```{r}
csv_fname <- "80_ra271.352_dec-29.642_MAXIJ1803TraPDB_andersson.csv"
path_to_csv <- here("data_raw", csv_fname)
data_df <- read_csv(path_to_csv, show_col_types = FALSE)

x <- data_df$mjd
y <- data_df$f_peak
y_err <- data_df$f_peak_err
x_star <- seq(from = min(x), to = max(x), length.out = 300)

data_df |> 
  ggplot() +
  aes(x = mjd, y = f_peak, 
      ymax = f_peak + f_peak_err, ymin = f_peak - f_peak_err) +
  geom_point(colour = "red") +
  geom_linerange(colour = "red") + 
  geom_rug(sides = "b", outside = TRUE, colour = "red") +
  coord_cartesian(clip = "off") +
  labs(title = csv_fname, x = "MJD", y = "Flux (Jy)") +
  theme_classic()
```

```{r}
#| include: false
summary(data_df[c("f_peak", "f_peak_err", "mjd")])
```

- The light curve has $N =$ `r NROW(data_df)` observations over a range of `r round(diff(range(x)), 2)` days.
- Observations are evenly spread over the time range.
- The shortest gap between observations is `r round(min(diff(x)), 2)` days.
- The longest gap between observations is `r round(max(diff(x)), 2)` days.
- The mean flux density is $\bar{y} =$ `r format(signif(mean(y),3), scientific = F)` Jy.
- The mean standard error in the observations is `r format(signif(mean(y_err),3), scientific = F)` Jy.
- The observational noise is very small relative to the brightness of the observations. 

# SE Basic Model

- Zero constant mean function.
- Squared Exponential kernel function.
- Homoskedastic noise.
- Wide prior on observational noise, uninformed by observational noise estimates.

$$y \sim \mathcal{N}(f(x), \sigma_\textrm{noise}^2)$$

$$f \sim \mathcal{GP}(\boldsymbol{0}, k(x,  x'))$$

$$k(x,x') = \eta^2 \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell^2}\right\}$$

$$\ell \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_\textrm{noise} \sim \mathcal{N}^+(0,1)$$

```{r}
basic_model <- cmdstan_model(stan_file = "stan/basic_model.stan")
```

```{r}
#| output: false
#| message: false
data_list <- list(N = length(x), 
                  x = x,
                  y = y,
                  x_star = x_star,
                  N_star = length(x_star))

basic_fit <- basic_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0)
```

## MCMC Results

```{r}
#| include: false
basic_fit$cmdstan_diagnose()
```

```{r}
basic_fit$print(variables = c("eta", "ell", "sigma"), digits = 5)
```

## MCMC Plots

```{r}
mcmc_plots(basic_fit, c("eta", "ell", "sigma"))
```

## Posterior Predictive Samples

```{r}
plot_postpred(basic_fit, x, y, y_err, x_star, "Basic Model")
```

The fitted model has a very long lengthscale, comparable to the length of the observational window. The estimated observational noise has a standard deviation is two orders of magnitude greater than that recorded in the original data. The combination of these parameters has lead to a very smooth fit that passes through the middle of the observed data points rather than through any datapoints themselves.

## PSD

```{r}
#| message: false
plot_PSD(basic_fit, title = "Basic Fit")
```

# SE Observational Errors Model

- Zero constant mean function.
- Squared exponential kernel function.
- Heteroskedastic (Gaussian) noise.
- Incorporate data on error in observations of each $y_i$.

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(\boldsymbol{0}, k(x,  x'))$$

$$k(x,x') = \eta^2 \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell^2}\right\}$$

$$\ell \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$

```{r}
err_model <- cmdstan_model("stan/err_model.stan")
```

```{r}
#| output: false
#| message: false
data_list <- list(N = length(x), 
                  x = x,
                  y = y,
                  y_stderr = y_err,
                  x_star = x_star,
                  N_star = length(x_star))

err_fit <- err_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

```{r}
#| include: false
err_fit$cmdstan_diagnose()
```

## MCMC Results

```{r}
err_fit$print(variables = c("eta", "ell", "sigma[1]"), digits = 6)
```

## MCMC Plots

```{r}
mcmc_plots(err_fit, c("eta", "ell", "sigma[1]"))
```

```{r fig.height=9}
mcmc_dens(err_fit$draws(), regex_pars = "sigma", facet_args = list(nrow = 7))
```

## Posterior Predictive Samples

```{r}
plot_postpred(err_fit, x, y, y_err, x_star, "Observational Errors Model")
```

By including the observed observational errors for setting priors on the Gaussian noise of each observation, the fitted median passes through each of the observed points.

## PSD

```{r}
#| message: false
plot_PSD(err_fit, title = "Observational Errors Model")
```  

# SE Non-zero flat mean function Model

- Constant mean function, learned from observations.
- Weak prior on mean function intercept.
- Squared exponential kernel function.
- Heteroskedastic (Gaussian) noise.
- Incorporate data on error in observations of each $y_i$.

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(C, k(x,  x'))$$

$$C \sim \mathcal{U}[-1,1]$$

$$k(x,x') = \eta^2 \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell^2}\right\}$$

$$\ell \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$

```{r}
flat_mean_model <- cmdstan_model("stan/flat_mean_model.stan")
```

```{r}
#| message: false
#| output: false
data_list <- list(N = length(x), 
                  x = x,
                  y = y,
                  y_stderr = y_err,
                  x_star = x_star,
                  N_star = length(x_star))

flat_mean_fit <- flat_mean_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

```{r}
#| include: false
flat_mean_fit$cmdstan_diagnose()
```

## MCMC Results

```{r}
flat_mean_fit$print(variables = c("eta", "ell", "C", "sigma[1]"), digits = 6)
```

## MCMC Plots

```{r}
mcmc_plots(flat_mean_fit, variables = c("eta", "ell", "C"))
```

## Posterior Predictive Samples

```{r}
plot_postpred(flat_mean_fit, x, y, y_err, x_star, "Flat Mean Function Model") + 
  geom_hline(aes(yintercept = mean(flat_mean_fit$draws("C"))), colour = "orange") 
```

## PSD

```{r}
#| message: false
plot_PSD(flat_mean_fit, title = "Flat Mean Function Model")
```

# SE Fixed constant mean function Model

- Constant mean function set at fixed value, e.g., mean of observations.
- Squared exponential kernel function.
- Heteroskedastic (Gaussian) noise.
- Incorporate data on error in observations of each $y_i$.

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(C, k(x,  x')),\quad C \in \mathbb{R}$$

$$k(x,x') = \eta^2 \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell^2}\right\}$$

$$\ell \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$

```{r}
fixed_mean_model <- cmdstan_model("stan/fixed_mean_model.stan")
```

## Mean Function = 0.061

```{r}
#| message: false
#| output: false
data_list <- list(N = length(x), 
                  x = x,
                  y = y,
                  y_stderr = y_err,
                  x_star = x_star,
                  N_star = length(x_star),
                  const_mean_value = 0.061)

fixed_mean_fit <- fixed_mean_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

```{r}
fixed_mean_fit$print(variables = c("eta", "ell", "sigma[1]"), digits = 5)
```

```{r}
plot_postpred(fixed_mean_fit, x, y, y_err, x_star, "Fixed Mean Function = 0.061") + 
  geom_hline(aes(yintercept = 0.061), colour = "orange") 
```

```{r}
#| message: false
plot_PSD(fixed_mean_fit, title = "Fixed Mean Function = 0.061")
```

## Mean Function = 0.059

```{r}
#| message: false
#| output: false
data_list <- list(N = length(x), 
                  x = x,
                  y = y,
                  y_stderr = y_err,
                  x_star = x_star,
                  N_star = length(x_star),
                  const_mean_value = 0.059)

fixed_mean_fit <- fixed_mean_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

```{r}
fixed_mean_fit$print(variables = c("eta", "ell", "sigma[1]"), digits = 6)
```

```{r}
plot_postpred(fixed_mean_fit, x, y, y_err, x_star, "Fixed Mean Function = 0.059") + 
  geom_hline(aes(yintercept = 0.059), colour = "orange") 
```

```{r}
#| message: false
plot_PSD(fixed_mean_fit, title = "Fixed Mean Function = 0.059")
```

## Mean Function = 0.056

```{r}
#| message: false
#| output: false
data_list <- list(N = length(x), 
                  x = x,
                  y = y,
                  y_stderr = y_err,
                  x_star = x_star,
                  N_star = length(x_star),
                  const_mean_value = 0.056)

fixed_mean_fit <- fixed_mean_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

```{r}
fixed_mean_fit$print(variables = c("eta", "ell", "sigma[1]"), digits = 5)
```

```{r}
plot_postpred(fixed_mean_fit, x, y, y_err, x_star, "Fixed Mean Function = 0.056") + 
  geom_hline(aes(yintercept = 0.056), colour = "orange") 
```

```{r}
#| message: false
plot_PSD(fixed_mean_fit, title = "Fixed Mean Function = 0.056")
```


# Matern 3/2 kernel

- Matern 3/2 covariance kernel
- Zero constant mean function

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(\boldsymbol{0}, k(x,  x'))$$

$$k(x,x') = \eta^2 \left( 1 + \frac{\sqrt{3(x - x')^2}}{\ell}\right) \exp\left\{ -\frac{\sqrt{3(x - x')^2}}{\ell}\right\}$$

$$\ell \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$

```{r}
matern32_model <- cmdstan_model(stan_file = "stan/matern32_model.stan")
```

```{r}
#| output: false
#| message: false
data_list <- list(N = length(data_df$mjd), 
                  x = data_df$mjd,
                  y = data_df$f_peak,
                  y_stderr = data_df$f_peak_err,
                  x_star = x_star,
                  N_star = length(x_star))

m32_fit <- matern32_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

```{r}
#| include: false
m32_fit$cmdstan_diagnose()
```

## MCMC Results

```{r}
m32_fit$print(variables = c("eta", "ell", "sigma[1]"), digits = 6)
```

## MCMC Plots

```{r}
mcmc_plots(m32_fit, c("eta", "ell", "sigma[1]"))
```

## Posterior Predictive Samples

```{r}
plot_postpred(m32_fit, x, y, y_err, x_star, "Matern 3/2 Model")
```

## PSD

```{r}
#| message: false
plot_PSD(m32_fit, title = "Matern 3/2 Model")
```

# SE + Matern 3/2 additive kernel

- Sum of squared exponential and Matern 3/2 kernels
- single output scale (marginal variance) hyperparameter
- zero constant mean function

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(\boldsymbol{0}, k(x,  x'))$$

$$k(x,x') = \eta^2 \left[ \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell_\mathrm{SE}^2}\right\} + \left( 1 + \frac{\sqrt{3(x - x')^2}}{\ell_\mathrm{M}}\right) \exp\left\{ -\frac{\sqrt{3(x - x')^2}}{\ell_\mathrm{M}}\right\} \right]$$

$$\ell_\mathrm{SE} \sim \mathrm{InvGamma}(5,5)$$

$$\ell_\mathrm{M} \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$


```{r}
SE_M32_model <- cmdstan_model(stan_file = "stan/SE_M32_model.stan")
```

```{r}
#| output: false
#| message: false
data_list <- list(N = length(data_df$mjd), 
                  x = data_df$mjd,
                  y = data_df$f_peak,
                  y_stderr = data_df$f_peak_err,
                  x_star = x_star,
                  N_star = length(x_star))

SE_M32_fit <- SE_M32_model$sample(
  data = data_list,
  seed = 1,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0
)
```

## MCMC Results

```{r}
SE_M32_fit$print(variables = c("eta", "ell_SE", "ell_M", "sigma[1]"), digits = 5)
```

## MCMC Plots

```{r}
mcmc_plots(SE_M32_fit, c("eta", "ell_SE", "ell_M"))
```

## Posterior Predictive Samples

```{r}
plot_postpred(SE_M32_fit, x, y, y_err, x_star, "SE + Matern 3/2 kernels Model")
```

## PSD

```{r}
#| message: false
plot_PSD(SE_M32_fit, title = "SE + Matern 3/2 kernels Model")
```

# SE x Matern 3/2 multiplicative kernel

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(\boldsymbol{0}, k(x,  x'))$$

$$k(x,x') = \eta^2 \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell_\mathrm{SE}^2}\right\}\left( 1 + \frac{\sqrt{3(x - x')^2}}{\ell_\mathrm{M}}\right) \exp\left\{ -\frac{\sqrt{3(x - x')^2}}{\ell_\mathrm{M}}\right\}$$

$$\ell_\mathrm{SE} \sim \mathrm{InvGamma}(5,5)$$

$$\ell_\mathrm{M} \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$


```{r}
SExM32_model <- cmdstan_model(stan_file = "stan/SExM32_model.stan")
```

```{r}
#| output: false
#| message: false
data_list <- list(N = length(data_df$mjd), 
                  x = data_df$mjd,
                  y = data_df$f_peak,
                  y_stderr = data_df$f_peak_err,
                  x_star = x_star,
                  N_star = length(x_star))

SExM32_fit <- SExM32_model$sample(
  data = data_list,
  seed = 2,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 0
)
```

```{r}
#| include: false
SExM32_fit$cmdstan_diagnose()
```

## MCMC Results

```{r}
SExM32_fit$print(variables = c("eta", "ell_SE", "ell_M", "sigma[1]", "f_star[1]"), digits = 6)
```

## MCMC Plots

```{r}
mcmc_plots(SExM32_fit, c("eta", "ell_SE", "ell_M"))
```

```{r fig.height=9}
mcmc_dens(SExM32_fit$draws(), regex_pars = "sigma", facet_args = list(nrow = 7))
```

## Posterior Predictive Samples

```{r}
plot_postpred(SExM32_fit, x, y, y_err, x_star, "SE x Matern 3/2 kernels Model")
```

## PSD

```{r}
#| message: false
plot_PSD(SExM32_fit, title = "SE x Matern 3/2 kernels Model")
```

# SE + Matern 3/2 + QP kernel

$$y_i \sim \mathcal{N}(f(x_i), \sigma_i^2)$$

$$f \sim \mathcal{GP}(\boldsymbol{0}, k(x,  x'))$$

$$k(x,x') = \eta^2 \left[ \exp\left\{ -\frac{2 \sin^2\left( \pi\frac{\sqrt{(x - x')^2}}{T}\right)}{\ell_\mathrm{P}^2}\right\} + \exp\left\{ -\frac{1}{2}\frac{(x - x')^2}{\ell_\mathrm{SE}^2}\right\} + \left( 1 + \frac{\sqrt{3(x - x')^2}}{\ell_\mathrm{M}}\right) \exp\left\{ -\frac{\sqrt{3(x - x')^2}}{\ell_\mathrm{M}}\right\} \right]$$

$$\ell_\mathrm{P} \sim \mathrm{InvGamma}(5,5)$$

$$\ell_\mathrm{SE} \sim \mathrm{InvGamma}(5,5)$$

$$\ell_\mathrm{M} \sim \mathrm{InvGamma}(5,5)$$

$$\eta \sim \mathcal{N}^+(0,1)$$

$$T \sim \mathcal{U}[\textrm{minimum gap in x}, \textrm{range of x}]$$

$$\sigma_i \sim \mathcal{N}^+(\textrm{stderr}(y_i), \mathrm{Var}(\textrm{stderr}(\boldsymbol{y})))$$


```{r}
SE_M32_P_model <- cmdstan_model(stan_file = "stan/SE_M32_P_model.stan")
```

```{r}
#| output: false
#| message: false
data_list <- list(N = length(data_df$mjd), 
                  x = data_df$mjd,
                  y = data_df$f_peak,
                  y_stderr = data_df$f_peak_err,
                  x_star = x_star,
                  N_star = length(x_star),
                  T_lb = min(diff(data_df$mjd)),
                  T_ub = diff(range(data_df$mjd)))

SE_M32_P_fit <- SE_M32_P_model$sample(
  data = data_list,
  seed = 3,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 0
)
```

## MCMC Results

```{r}
SE_M32_P_fit$print(variables = c("eta", "ell_SE", "ell_M", "ell_P", "T"), digits = 4)
```

## MCMC Plots

```{r}
mcmc_plots(SE_M32_P_fit, c("eta", "ell_SE", "ell_M", "ell_P", "T"))
```

```{r fig.height=9}
mcmc_dens(SE_M32_P_fit$draws(), regex_pars = "sigma", facet_args = list(nrow = 7))
```

## Posterior Predictive Samples

```{r}
plot_postpred(SE_M32_P_fit, x, y, y_err, x_star, "SE + Matern 3/2 + Periodic Model")
```

## PSD

```{r}
#| message: false
plot_PSD(SE_M32_P_fit, title = "SE + Matern 3/2 + Periodic Model")
```

